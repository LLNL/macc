{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg',warn=False)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import Markdown as md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "fdir = './outs_test'\n",
    "modeldir = './pretrained_model/'\n",
    "ae_dir = './wae_metric/pretrained_model/'\n",
    "batch_size = 100\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "\n",
    "if not os.path.exists(modeldir):\n",
    "    os.makedirs(modeldir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wae_metric.run_WAE import LATENT_SPACE_DIM, load_dataset\n",
    "#these utilities are loaded from the autoencoder scripts to keep them consistent\n",
    "\n",
    "jag_inp, jag_sca, jag_img = load_dataset('./data/')\n",
    "LATENT_DIM = LATENT_SPACE_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Dataset Information---------------\n",
      "Input parameters: (10000, 5), Output Scalars: (10000, 15), Output Images: (10000, 16384)\n"
     ]
    }
   ],
   "source": [
    "print('---------------Dataset Information---------------\\nInput parameters: {}, Output Scalars: {}, Output Images: {}'.format(jag_inp.shape,\n",
    "                                                                           jag_sca.shape,\n",
    "                                                                           jag_img.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7763 6764 6662 5371 7257 2963 1321 6730 9597 3155]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4321) #this is the random seed used during training.  \n",
    "tr_id = np.random.choice(jag_sca.shape[0],int(jag_sca.shape[0]*0.8),replace=False)\n",
    "print(tr_id[:10])\n",
    "te_id = list(set(range(jag_sca.shape[0])) - set(tr_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = jag_inp[tr_id,:]\n",
    "y_sca_train = jag_sca[tr_id,:]\n",
    "y_img_train = jag_img[tr_id,:]\n",
    "\n",
    "np.random.shuffle(te_id)\n",
    "\n",
    "X_test = jag_inp[te_id,:]\n",
    "y_sca_test = jag_sca[te_id,:]\n",
    "y_img_test = jag_img[te_id,:]\n",
    "y_img_test_mb = y_img_test[-100:,:]\n",
    "\n",
    "y_img_test_mb = y_img_test_mb.reshape(100,64,64,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Ground Truth Images in \"fdir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot\n",
    "\n",
    "for k in range(4):\n",
    "        fig = plot(y_img_test_mb[:,:,:,k],immax=np.max(y_img_test_mb[:,:,:,k].reshape(-1,4096),axis=1),\n",
    "                   immin=np.min(y_img_test_mb[:,:,:,k].reshape(-1,4096),axis=1))\n",
    "        plt.savefig('{}/gt_img_{}_{}.png'\n",
    "                    .format(fdir,str(k).zfill(3),str(k)), bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_x = X_train.shape[1]\n",
    "dim_y_sca = y_sca_train.shape[1]\n",
    "dim_y_img = y_img_train.shape[1]\n",
    "dim_y_img_latent = LATENT_DIM #latent space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Computational Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelsv2 import cycModel_MM\n",
    "import wae_metric.model_AVB as wae\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "y_sca = tf.placeholder(tf.float32, shape=[None, dim_y_sca])\n",
    "y_img = tf.placeholder(tf.float32, shape=[None, dim_y_img])\n",
    "x = tf.placeholder(tf.float32, shape=[None, dim_x])\n",
    "train_mode = tf.placeholder(tf.bool,name='train_mode')\n",
    "\n",
    "y_mm = tf.concat([y_img,y_sca],axis=1)\n",
    "\n",
    "### 1. Map outputs (images, scalars) --> latent space with pre-trained autoencoder\n",
    "\n",
    "y_latent_img = wae.gen_encoder_FCN(y_mm, dim_y_img_latent,train_mode)\n",
    "\n",
    "### 2. Next, build the CycleGAN that learns to map input params <--> latent vector\n",
    "cycGAN_params = {'input_params':x, \n",
    "                 'outputs':y_latent_img,\n",
    "                 'param_dim':dim_x,\n",
    "                 'output_dim':dim_y_img_latent,\n",
    "                 'L_adv':1e-2, # controls \"physical\" consistency\n",
    "                 'L_cyc':1e-1, # controls cyclical consustency\n",
    "                 'L_rec':1.}   # controls fidelity of surrogate\n",
    "\n",
    "JagNet_MM = cycModel_MM(**cycGAN_params)\n",
    "JagNet_MM.run(train_mode)\n",
    "### 3. Decode the predictions from the CycleGAN into output space of images and scalars\n",
    "y_img_out = wae.var_decoder_FCN(JagNet_MM.output_fake, dim_y_img+dim_y_sca,train_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wae_metric/pretrained_model/model_99999.ckpt\n",
      "************ Image Metric Restored! **************\n",
      "INFO:tensorflow:Restoring parameters from ./pretrained_model/model_99500.ckpt\n",
      "************ Model restored! **************\n"
     ]
    }
   ],
   "source": [
    "t_vars = tf.global_variables()\n",
    "m_vars = [var for var in t_vars if 'wae' in var.name]\n",
    "metric_saver = tf.train.Saver(m_vars)\n",
    "saver = tf.train.Saver(list(set(t_vars)-set(m_vars)))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state(modeldir)\n",
    "ckpt_metric = tf.train.get_checkpoint_state(ae_dir)\n",
    "\n",
    "if ckpt_metric and ckpt_metric.model_checkpoint_path:\n",
    "       metric_saver.restore(sess, ckpt_metric.model_checkpoint_path)\n",
    "       print(\"************ Image Metric Restored! **************\")\n",
    "\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    print(\"************ Model restored! **************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import test_imgs_plot\n",
    "\n",
    "for it in range(50000):\n",
    "\n",
    "        randid = np.random.choice(X_train.shape[0],batch_size,replace=False)\n",
    "        x_mb = X_train[randid,:]\n",
    "        y_img_mb = y_img_train[randid,:]\n",
    "        y_sca_mb = y_sca_train[randid,:]\n",
    "\n",
    "        fd = {x: x_mb, y_sca: y_sca_mb,y_img:y_img_mb,train_mode:True}\n",
    "        _, dloss,gloss0,gloss1 = sess.run([JagNet_MM.D_solver,JagNet_MM.loss_disc,\n",
    "                                           JagNet_MM.loss_gen0,JagNet_MM.loss_gen1],\n",
    "                                          feed_dict=fd)\n",
    "        _ = sess.run([JagNet_MM.G0_solver],feed_dict=fd)\n",
    "\n",
    "        if it%100 == 0:\n",
    "            print('Iter: {}; forward loss: {:.4}; inverse loss: {:.4}'\n",
    "                  .format(it, gloss0, gloss1))\n",
    "        if it%500==0:\n",
    "            nTest = 16\n",
    "            x_test_mb = X_test[-nTest:,:]\n",
    "            samples,samples_x = sess.run([y_img_out,JagNet_MM.input_cyc],\n",
    "                                       feed_dict={x: x_test_mb,train_mode:False})\n",
    "            data_dict= {}\n",
    "            data_dict['samples'] = samples\n",
    "            data_dict['samples_x'] = samples_x\n",
    "            data_dict['y_sca'] = y_sca_test\n",
    "            data_dict['y_img'] = y_img_test\n",
    "            data_dict['x'] = x_test_mb\n",
    "\n",
    "            test_imgs_plot(fdir,it,data_dict)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
