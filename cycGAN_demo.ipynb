{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg',warn=False)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import Markdown as md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fdir = './outs_test'\n",
    "modeldir = './pretrained_model/'\n",
    "ae_dir = './wae_metric/pretrained_model/'\n",
    "batch_size = 100\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "\n",
    "if not os.path.exists(modeldir):\n",
    "    os.makedirs(modeldir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wae_metric.run_WAE import LATENT_SPACE_DIM, load_dataset\n",
    "#these utilities are loaded from the autoencoder scripts to keep them consistent\n",
    "\n",
    "jag_inp, jag_sca, jag_img = load_dataset('./data/')\n",
    "LATENT_DIM = LATENT_SPACE_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Dataset Information---------------\n",
      "Input parameters: (10000, 5), Output Scalars: (10000, 15), Output Images: (10000, 16384)\n"
     ]
    }
   ],
   "source": [
    "print('---------------Dataset Information---------------\\nInput parameters: {}, Output Scalars: {}, Output Images: {}'.format(jag_inp.shape,\n",
    "                                                                           jag_sca.shape,\n",
    "                                                                           jag_img.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7763 6764 6662 5371 7257 2963 1321 6730 9597 3155]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4321) #this is the random seed used during training.  \n",
    "tr_id = np.random.choice(jag_sca.shape[0],int(jag_sca.shape[0]*0.8),replace=False)\n",
    "print(tr_id[:10])\n",
    "te_id = list(set(range(jag_sca.shape[0])) - set(tr_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = jag_inp[tr_id,:]\n",
    "y_sca_train = jag_sca[tr_id,:]\n",
    "y_img_train = jag_img[tr_id,:]\n",
    "\n",
    "np.random.shuffle(te_id)\n",
    "\n",
    "X_test = jag_inp[te_id,:]\n",
    "y_sca_test = jag_sca[te_id,:]\n",
    "y_img_test = jag_img[te_id,:]\n",
    "y_img_test_mb = y_img_test[-100:,:]\n",
    "\n",
    "y_img_test_mb = y_img_test_mb.reshape(100,64,64,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Ground Truth Images in \"fdir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot\n",
    "\n",
    "for k in range(4):\n",
    "        fig = plot(y_img_test_mb[:,:,:,k],immax=np.max(y_img_test_mb[:,:,:,k].reshape(-1,4096),axis=1),\n",
    "                   immin=np.min(y_img_test_mb[:,:,:,k].reshape(-1,4096),axis=1))\n",
    "        plt.savefig('{}/gt_img_{}_{}.png'\n",
    "                    .format(fdir,str(k).zfill(3),str(k)), bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_x = X_train.shape[1]\n",
    "dim_y_sca = y_sca_train.shape[1]\n",
    "dim_y_img = y_img_train.shape[1]\n",
    "dim_y_img_latent = LATENT_DIM #latent space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Computational Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /net/ryan-dev/srv/nfs/ryan-data/ws/macc/wae_metric/model_AVB.py:19: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /net/ryan-dev/srv/nfs/ryan-data/ws/macc/wae_metric/model_AVB.py:27: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /net/ryan-dev/srv/nfs/ryan-data/ws/macc/utils.py:62: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/python3.6c/lib64/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /net/ryan-dev/srv/nfs/ryan-data/ws/macc/modelsv2.py:189: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /net/ryan-dev/srv/nfs/ryan-data/ws/macc/modelsv2.py:194: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modelsv2 import cycModel_MM\n",
    "import wae_metric.model_AVB as wae\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "y_sca = tf.placeholder(tf.float32, shape=[None, dim_y_sca])\n",
    "y_img = tf.placeholder(tf.float32, shape=[None, dim_y_img])\n",
    "x = tf.placeholder(tf.float32, shape=[None, dim_x])\n",
    "train_mode = tf.placeholder(tf.bool,name='train_mode')\n",
    "\n",
    "y_mm = tf.concat([y_img,y_sca],axis=1)\n",
    "\n",
    "### 1. Map outputs (images, scalars) --> latent space with pre-trained autoencoder\n",
    "\n",
    "y_latent_img = wae.gen_encoder_FCN(y_mm, dim_y_img_latent,train_mode)\n",
    "\n",
    "### 2. Next, build the CycleGAN that learns to map input params <--> latent vector\n",
    "cycGAN_params = {'input_params':x, \n",
    "                 'outputs':y_latent_img,\n",
    "                 'param_dim':dim_x,\n",
    "                 'output_dim':dim_y_img_latent,\n",
    "                 'L_adv':1e-2, # controls \"physical\" consistency\n",
    "                 'L_cyc':1e-1, # controls cyclical consustency\n",
    "                 'L_rec':1.}   # controls fidelity of surrogate\n",
    "\n",
    "JagNet_MM = cycModel_MM(**cycGAN_params)\n",
    "JagNet_MM.run(train_mode)\n",
    "### 3. Decode the predictions from the CycleGAN into output space of images and scalars\n",
    "y_img_out = wae.var_decoder_FCN(JagNet_MM.output_fake, dim_y_img+dim_y_sca,train_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vars = tf.global_variables()\n",
    "m_vars = [var for var in t_vars if 'wae' in var.name]\n",
    "metric_saver = tf.train.Saver(m_vars)\n",
    "saver = tf.train.Saver(list(set(t_vars)-set(m_vars)))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state(modeldir)\n",
    "ckpt_metric = tf.train.get_checkpoint_state(ae_dir)\n",
    "\n",
    "if ckpt_metric and ckpt_metric.model_checkpoint_path:\n",
    "       metric_saver.restore(sess, ckpt_metric.model_checkpoint_path)\n",
    "       print(\"************ Image Metric Restored! **************\")\n",
    "\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    print(\"************ Model restored! **************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0; forward loss: 0.8366; inverse loss: 0.8563\n",
      "Iter: 100; forward loss: 0.3394; inverse loss: 0.3927\n",
      "Iter: 200; forward loss: 0.3344; inverse loss: 0.4027\n",
      "Iter: 300; forward loss: 0.3136; inverse loss: 0.5362\n",
      "Iter: 400; forward loss: 0.2867; inverse loss: 0.3845\n",
      "Iter: 500; forward loss: 0.3277; inverse loss: 0.2795\n",
      "Iter: 600; forward loss: 0.3171; inverse loss: 0.3638\n",
      "Iter: 700; forward loss: 0.2952; inverse loss: 0.2806\n",
      "Iter: 800; forward loss: 0.3341; inverse loss: 0.2698\n",
      "Iter: 900; forward loss: 0.2615; inverse loss: 0.2641\n",
      "Iter: 1000; forward loss: 0.2881; inverse loss: 0.2636\n",
      "Iter: 1100; forward loss: 0.3109; inverse loss: 0.2461\n",
      "Iter: 1200; forward loss: 0.3141; inverse loss: 0.2312\n",
      "Iter: 1300; forward loss: 0.3082; inverse loss: 0.2282\n",
      "Iter: 1400; forward loss: 0.2976; inverse loss: 0.2176\n",
      "Iter: 1500; forward loss: 0.3538; inverse loss: 0.2836\n",
      "Iter: 1600; forward loss: 0.3353; inverse loss: 0.2377\n",
      "Iter: 1700; forward loss: 0.2887; inverse loss: 0.198\n",
      "Iter: 1800; forward loss: 0.2717; inverse loss: 0.2078\n",
      "Iter: 1900; forward loss: 0.2682; inverse loss: 0.2117\n",
      "Iter: 2000; forward loss: 0.2828; inverse loss: 0.2029\n",
      "Iter: 2100; forward loss: 0.2643; inverse loss: 0.1885\n",
      "Iter: 2200; forward loss: 0.2857; inverse loss: 0.1862\n",
      "Iter: 2300; forward loss: 0.2888; inverse loss: 0.2248\n",
      "Iter: 2400; forward loss: 0.2901; inverse loss: 0.2049\n",
      "Iter: 2500; forward loss: 0.3648; inverse loss: 0.2646\n",
      "Iter: 2600; forward loss: 0.2854; inverse loss: 0.1674\n",
      "Iter: 2700; forward loss: 0.2713; inverse loss: 0.1606\n",
      "Iter: 2800; forward loss: 0.3534; inverse loss: 0.1827\n",
      "Iter: 2900; forward loss: 0.2734; inverse loss: 0.1902\n",
      "Iter: 3000; forward loss: 0.3037; inverse loss: 0.1632\n",
      "Iter: 3100; forward loss: 0.2972; inverse loss: 0.1602\n",
      "Iter: 3200; forward loss: 0.2935; inverse loss: 0.1696\n",
      "Iter: 3300; forward loss: 0.3394; inverse loss: 0.1492\n",
      "Iter: 3400; forward loss: 0.2726; inverse loss: 0.1651\n",
      "Iter: 3500; forward loss: 0.2908; inverse loss: 0.1521\n",
      "Iter: 3600; forward loss: 0.291; inverse loss: 0.1441\n",
      "Iter: 3700; forward loss: 0.2772; inverse loss: 0.1484\n",
      "Iter: 3800; forward loss: 0.3067; inverse loss: 0.141\n",
      "Iter: 3900; forward loss: 0.287; inverse loss: 0.1351\n",
      "Iter: 4000; forward loss: 0.3013; inverse loss: 0.1404\n",
      "Iter: 4100; forward loss: 0.2379; inverse loss: 0.1412\n",
      "Iter: 4200; forward loss: 0.2219; inverse loss: 0.09028\n",
      "Iter: 4300; forward loss: 0.1797; inverse loss: 0.09049\n",
      "Iter: 4400; forward loss: 0.1831; inverse loss: 0.07435\n",
      "Iter: 4500; forward loss: 0.2653; inverse loss: 0.0451\n",
      "Iter: 4600; forward loss: 0.2068; inverse loss: 0.05131\n",
      "Iter: 4700; forward loss: 0.2881; inverse loss: 0.03996\n",
      "Iter: 4800; forward loss: 0.2494; inverse loss: 0.04239\n",
      "Iter: 4900; forward loss: 0.1977; inverse loss: 0.04419\n",
      "Iter: 5000; forward loss: 0.2537; inverse loss: 0.04356\n",
      "Iter: 5100; forward loss: 0.2124; inverse loss: 0.05351\n",
      "Iter: 5200; forward loss: 0.2892; inverse loss: 0.05443\n",
      "Iter: 5300; forward loss: 0.2104; inverse loss: 0.0525\n",
      "Iter: 5400; forward loss: 0.2865; inverse loss: 0.04422\n",
      "Iter: 5500; forward loss: 0.2276; inverse loss: 0.0547\n",
      "Iter: 5600; forward loss: 0.2001; inverse loss: 0.04755\n",
      "Iter: 5700; forward loss: 0.2303; inverse loss: 0.06109\n",
      "Iter: 5800; forward loss: 0.2157; inverse loss: 0.04584\n",
      "Iter: 5900; forward loss: 0.2711; inverse loss: 0.05511\n",
      "Iter: 6000; forward loss: 0.2593; inverse loss: 0.04999\n",
      "Iter: 6100; forward loss: 0.248; inverse loss: 0.05171\n",
      "Iter: 6200; forward loss: 0.2026; inverse loss: 0.05174\n",
      "Iter: 6300; forward loss: 0.2632; inverse loss: 0.05276\n",
      "Iter: 6400; forward loss: 0.2181; inverse loss: 0.05643\n",
      "Iter: 6500; forward loss: 0.312; inverse loss: 0.05332\n",
      "Iter: 6600; forward loss: 0.2044; inverse loss: 0.05717\n",
      "Iter: 6700; forward loss: 0.2462; inverse loss: 0.0556\n",
      "Iter: 6800; forward loss: 0.2684; inverse loss: 0.06788\n",
      "Iter: 6900; forward loss: 0.2567; inverse loss: 0.0501\n",
      "Iter: 7000; forward loss: 0.2364; inverse loss: 0.05384\n",
      "Iter: 7100; forward loss: 0.303; inverse loss: 0.06321\n",
      "Iter: 7200; forward loss: 0.2299; inverse loss: 0.06042\n",
      "Iter: 7300; forward loss: 0.2311; inverse loss: 0.05084\n",
      "Iter: 7400; forward loss: 0.2082; inverse loss: 0.04564\n",
      "Iter: 7500; forward loss: 0.2192; inverse loss: 0.05946\n",
      "Iter: 7600; forward loss: 0.2877; inverse loss: 0.05096\n",
      "Iter: 7700; forward loss: 0.2887; inverse loss: 0.06129\n",
      "Iter: 7800; forward loss: 0.2481; inverse loss: 0.05088\n",
      "Iter: 7900; forward loss: 0.2267; inverse loss: 0.05427\n",
      "Iter: 8000; forward loss: 0.2329; inverse loss: 0.0494\n",
      "Iter: 8100; forward loss: 0.2369; inverse loss: 0.05685\n",
      "Iter: 8200; forward loss: 0.2843; inverse loss: 0.0734\n",
      "Iter: 8300; forward loss: 0.2285; inverse loss: 0.05641\n",
      "Iter: 8400; forward loss: 0.2001; inverse loss: 0.06299\n",
      "Iter: 8500; forward loss: 0.1912; inverse loss: 0.0469\n",
      "Iter: 8600; forward loss: 0.204; inverse loss: 0.05498\n",
      "Iter: 8700; forward loss: 0.2379; inverse loss: 0.04919\n",
      "Iter: 8800; forward loss: 0.1896; inverse loss: 0.0573\n",
      "Iter: 8900; forward loss: 0.2009; inverse loss: 0.04623\n",
      "Iter: 9000; forward loss: 0.1874; inverse loss: 0.05253\n",
      "Iter: 9100; forward loss: 0.2302; inverse loss: 0.05853\n",
      "Iter: 9200; forward loss: 0.2466; inverse loss: 0.0523\n",
      "Iter: 9300; forward loss: 0.1924; inverse loss: 0.05099\n",
      "Iter: 9400; forward loss: 0.2154; inverse loss: 0.05321\n",
      "Iter: 9500; forward loss: 0.2647; inverse loss: 0.05559\n",
      "Iter: 9600; forward loss: 0.2605; inverse loss: 0.06149\n",
      "Iter: 9700; forward loss: 0.2512; inverse loss: 0.05866\n",
      "Iter: 9800; forward loss: 0.2148; inverse loss: 0.04942\n",
      "Iter: 9900; forward loss: 0.2108; inverse loss: 0.05483\n",
      "Iter: 10000; forward loss: 0.2652; inverse loss: 0.05509\n",
      "Iter: 10100; forward loss: 0.2539; inverse loss: 0.06035\n",
      "Iter: 10200; forward loss: 0.1958; inverse loss: 0.05469\n",
      "Iter: 10300; forward loss: 0.2294; inverse loss: 0.05116\n",
      "Iter: 10400; forward loss: 0.2462; inverse loss: 0.05761\n",
      "Iter: 10500; forward loss: 0.2355; inverse loss: 0.06193\n",
      "Iter: 10600; forward loss: 0.2224; inverse loss: 0.05964\n",
      "Iter: 10700; forward loss: 0.296; inverse loss: 0.05152\n",
      "Iter: 10800; forward loss: 0.2362; inverse loss: 0.0553\n",
      "Iter: 10900; forward loss: 0.2547; inverse loss: 0.05884\n",
      "Iter: 11000; forward loss: 0.2525; inverse loss: 0.05278\n",
      "Iter: 11100; forward loss: 0.2122; inverse loss: 0.05048\n",
      "Iter: 11200; forward loss: 0.2289; inverse loss: 0.06415\n",
      "Iter: 11300; forward loss: 0.2027; inverse loss: 0.04903\n",
      "Iter: 11400; forward loss: 0.2194; inverse loss: 0.0515\n",
      "Iter: 11500; forward loss: 0.2225; inverse loss: 0.05989\n",
      "Iter: 11600; forward loss: 0.1972; inverse loss: 0.04606\n",
      "Iter: 11700; forward loss: 0.1924; inverse loss: 0.05208\n",
      "Iter: 11800; forward loss: 0.2369; inverse loss: 0.05274\n",
      "Iter: 11900; forward loss: 0.2014; inverse loss: 0.05197\n",
      "Iter: 12000; forward loss: 0.2199; inverse loss: 0.05258\n",
      "Iter: 12100; forward loss: 0.1931; inverse loss: 0.05925\n",
      "Iter: 12200; forward loss: 0.2779; inverse loss: 0.06105\n",
      "Iter: 12300; forward loss: 0.209; inverse loss: 0.06231\n",
      "Iter: 12400; forward loss: 0.2358; inverse loss: 0.06063\n",
      "Iter: 12500; forward loss: 0.2264; inverse loss: 0.0593\n",
      "Iter: 12600; forward loss: 0.2076; inverse loss: 0.05751\n",
      "Iter: 12700; forward loss: 0.2286; inverse loss: 0.05252\n",
      "Iter: 12800; forward loss: 0.2046; inverse loss: 0.05978\n",
      "Iter: 12900; forward loss: 0.2776; inverse loss: 0.04885\n",
      "Iter: 13000; forward loss: 0.1705; inverse loss: 0.05515\n",
      "Iter: 13100; forward loss: 0.2096; inverse loss: 0.06531\n",
      "Iter: 13200; forward loss: 0.2208; inverse loss: 0.05686\n",
      "Iter: 13300; forward loss: 0.1952; inverse loss: 0.04927\n",
      "Iter: 13400; forward loss: 0.2103; inverse loss: 0.05359\n",
      "Iter: 13500; forward loss: 0.2127; inverse loss: 0.04492\n",
      "Iter: 13600; forward loss: 0.2783; inverse loss: 0.04477\n",
      "Iter: 13700; forward loss: 0.2439; inverse loss: 0.05417\n",
      "Iter: 13800; forward loss: 0.1934; inverse loss: 0.05735\n",
      "Iter: 13900; forward loss: 0.2324; inverse loss: 0.05628\n",
      "Iter: 14000; forward loss: 0.2132; inverse loss: 0.06518\n",
      "Iter: 14100; forward loss: 0.2059; inverse loss: 0.06659\n",
      "Iter: 14200; forward loss: 0.235; inverse loss: 0.06075\n",
      "Iter: 14300; forward loss: 0.2195; inverse loss: 0.05731\n",
      "Iter: 14400; forward loss: 0.2864; inverse loss: 0.06305\n",
      "Iter: 14500; forward loss: 0.3225; inverse loss: 0.05382\n",
      "Iter: 14600; forward loss: 0.2394; inverse loss: 0.04863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 14700; forward loss: 0.184; inverse loss: 0.0708\n",
      "Iter: 14800; forward loss: 0.1874; inverse loss: 0.06602\n",
      "Iter: 14900; forward loss: 0.2018; inverse loss: 0.06762\n",
      "Iter: 15000; forward loss: 0.2169; inverse loss: 0.06607\n",
      "Iter: 15100; forward loss: 0.1862; inverse loss: 0.05096\n",
      "Iter: 15200; forward loss: 0.1982; inverse loss: 0.05335\n",
      "Iter: 15300; forward loss: 0.1958; inverse loss: 0.0571\n",
      "Iter: 15400; forward loss: 0.1826; inverse loss: 0.04686\n",
      "Iter: 15500; forward loss: 0.216; inverse loss: 0.05944\n",
      "Iter: 15600; forward loss: 0.2008; inverse loss: 0.05747\n",
      "Iter: 15700; forward loss: 0.2652; inverse loss: 0.06857\n",
      "Iter: 15800; forward loss: 0.207; inverse loss: 0.05925\n",
      "Iter: 15900; forward loss: 0.2302; inverse loss: 0.04838\n",
      "Iter: 16000; forward loss: 0.1915; inverse loss: 0.06116\n",
      "Iter: 16100; forward loss: 0.2762; inverse loss: 0.05574\n",
      "Iter: 16200; forward loss: 0.2165; inverse loss: 0.05209\n",
      "Iter: 16300; forward loss: 0.2001; inverse loss: 0.05662\n",
      "Iter: 16400; forward loss: 0.2197; inverse loss: 0.05893\n",
      "Iter: 16500; forward loss: 0.2781; inverse loss: 0.06807\n",
      "Iter: 16600; forward loss: 0.2472; inverse loss: 0.06388\n",
      "Iter: 16700; forward loss: 0.2086; inverse loss: 0.05937\n",
      "Iter: 16800; forward loss: 0.1951; inverse loss: 0.05185\n",
      "Iter: 16900; forward loss: 0.2208; inverse loss: 0.04954\n",
      "Iter: 17000; forward loss: 0.2301; inverse loss: 0.05144\n",
      "Iter: 17100; forward loss: 0.2694; inverse loss: 0.06092\n",
      "Iter: 17200; forward loss: 0.2564; inverse loss: 0.07263\n",
      "Iter: 17300; forward loss: 0.2822; inverse loss: 0.05711\n",
      "Iter: 17400; forward loss: 0.2046; inverse loss: 0.05268\n",
      "Iter: 17500; forward loss: 0.1799; inverse loss: 0.05712\n",
      "Iter: 17600; forward loss: 0.1784; inverse loss: 0.04901\n",
      "Iter: 17700; forward loss: 0.2907; inverse loss: 0.06299\n",
      "Iter: 17800; forward loss: 0.2369; inverse loss: 0.06346\n",
      "Iter: 17900; forward loss: 0.1692; inverse loss: 0.04929\n",
      "Iter: 18000; forward loss: 0.1923; inverse loss: 0.05942\n",
      "Iter: 18100; forward loss: 0.1799; inverse loss: 0.04887\n",
      "Iter: 18200; forward loss: 0.2259; inverse loss: 0.06751\n",
      "Iter: 18300; forward loss: 0.217; inverse loss: 0.05914\n",
      "Iter: 18400; forward loss: 0.209; inverse loss: 0.06165\n",
      "Iter: 18500; forward loss: 0.2101; inverse loss: 0.06403\n",
      "Iter: 18600; forward loss: 0.1879; inverse loss: 0.06924\n",
      "Iter: 18700; forward loss: 0.1978; inverse loss: 0.05581\n",
      "Iter: 18800; forward loss: 0.2361; inverse loss: 0.06157\n",
      "Iter: 18900; forward loss: 0.2008; inverse loss: 0.05981\n",
      "Iter: 19000; forward loss: 0.2185; inverse loss: 0.05857\n",
      "Iter: 19100; forward loss: 0.1947; inverse loss: 0.06567\n",
      "Iter: 19200; forward loss: 0.2201; inverse loss: 0.05738\n",
      "Iter: 19300; forward loss: 0.1672; inverse loss: 0.05695\n",
      "Iter: 19400; forward loss: 0.1976; inverse loss: 0.07391\n",
      "Iter: 19500; forward loss: 0.2462; inverse loss: 0.06639\n",
      "Iter: 19600; forward loss: 0.22; inverse loss: 0.0543\n",
      "Iter: 19700; forward loss: 0.2068; inverse loss: 0.06311\n",
      "Iter: 19800; forward loss: 0.2002; inverse loss: 0.05866\n",
      "Iter: 19900; forward loss: 0.2658; inverse loss: 0.06343\n",
      "Iter: 20000; forward loss: 0.2003; inverse loss: 0.05509\n",
      "Iter: 20100; forward loss: 0.2229; inverse loss: 0.06959\n",
      "Iter: 20200; forward loss: 0.1774; inverse loss: 0.0546\n",
      "Iter: 20300; forward loss: 0.2487; inverse loss: 0.07005\n",
      "Iter: 20400; forward loss: 0.1996; inverse loss: 0.05764\n",
      "Iter: 20500; forward loss: 0.2515; inverse loss: 0.06729\n",
      "Iter: 20600; forward loss: 0.1703; inverse loss: 0.04381\n",
      "Iter: 20700; forward loss: 0.239; inverse loss: 0.06804\n",
      "Iter: 20800; forward loss: 0.1988; inverse loss: 0.05191\n",
      "Iter: 20900; forward loss: 0.2544; inverse loss: 0.05727\n",
      "Iter: 21000; forward loss: 0.1947; inverse loss: 0.06695\n",
      "Iter: 21100; forward loss: 0.2068; inverse loss: 0.0559\n",
      "Iter: 21200; forward loss: 0.2258; inverse loss: 0.06968\n",
      "Iter: 21300; forward loss: 0.2716; inverse loss: 0.08251\n",
      "Iter: 21400; forward loss: 0.2125; inverse loss: 0.05289\n",
      "Iter: 21500; forward loss: 0.2098; inverse loss: 0.05743\n",
      "Iter: 21600; forward loss: 0.2171; inverse loss: 0.05898\n",
      "Iter: 21700; forward loss: 0.2073; inverse loss: 0.06337\n",
      "Iter: 21800; forward loss: 0.1946; inverse loss: 0.07013\n",
      "Iter: 21900; forward loss: 0.204; inverse loss: 0.05819\n",
      "Iter: 22000; forward loss: 0.183; inverse loss: 0.05444\n",
      "Iter: 22100; forward loss: 0.1787; inverse loss: 0.04835\n",
      "Iter: 22200; forward loss: 0.1929; inverse loss: 0.06339\n",
      "Iter: 22300; forward loss: 0.1846; inverse loss: 0.06133\n",
      "Iter: 22400; forward loss: 0.1768; inverse loss: 0.06057\n",
      "Iter: 22500; forward loss: 0.1898; inverse loss: 0.05176\n"
     ]
    }
   ],
   "source": [
    "from utils import test_imgs_plot\n",
    "\n",
    "for it in range(50000):\n",
    "\n",
    "        randid = np.random.choice(X_train.shape[0],batch_size,replace=False)\n",
    "        x_mb = X_train[randid,:]\n",
    "        y_img_mb = y_img_train[randid,:]\n",
    "        y_sca_mb = y_sca_train[randid,:]\n",
    "\n",
    "        fd = {x: x_mb, y_sca: y_sca_mb,y_img:y_img_mb,train_mode:True}\n",
    "        _, dloss,gloss0,gloss1 = sess.run([JagNet_MM.D_solver,JagNet_MM.loss_disc,\n",
    "                                           JagNet_MM.loss_gen0,JagNet_MM.loss_gen1],\n",
    "                                          feed_dict=fd)\n",
    "        _ = sess.run([JagNet_MM.G0_solver],feed_dict=fd)\n",
    "\n",
    "        if it%100 == 0:\n",
    "            print('Iter: {}; forward loss: {:.4}; inverse loss: {:.4}'\n",
    "                  .format(it, gloss0, gloss1))\n",
    "        if it%500==0:\n",
    "            nTest = 16\n",
    "            x_test_mb = X_test[-nTest:,:]\n",
    "            samples,samples_x = sess.run([y_img_out,JagNet_MM.input_cyc],\n",
    "                                       feed_dict={x: x_test_mb,train_mode:False})\n",
    "            data_dict= {}\n",
    "            data_dict['samples'] = samples\n",
    "            data_dict['samples_x'] = samples_x\n",
    "            data_dict['y_sca'] = y_sca_test\n",
    "            data_dict['y_img'] = y_img_test\n",
    "            data_dict['x'] = x_test_mb\n",
    "\n",
    "            test_imgs_plot(fdir,it,data_dict)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
